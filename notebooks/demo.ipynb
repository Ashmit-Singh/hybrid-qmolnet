{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß¨ Hybrid QMolNet: Quantum-Classical Drug Molecule Property Prediction\n",
    "\n",
    "## A Complete Tutorial and Demonstration\n",
    "\n",
    "This notebook provides a comprehensive walkthrough of the **Hybrid Graph Neural Network + Variational Quantum Neural Network** for predicting drug molecule properties from SMILES strings.\n",
    "\n",
    "### Pipeline Overview\n",
    "\n",
    "```\n",
    "SMILES ‚Üí RDKit Molecular Graph ‚Üí GNN Encoder ‚Üí Embedding Compression ‚Üí \n",
    "         Variational Quantum Circuit ‚Üí Classifier ‚Üí Property Prediction\n",
    "```\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "1. **Molecular Graph Construction** - Converting SMILES to PyTorch Geometric graphs\n",
    "2. **GNN Encoding** - Message-passing neural networks for molecular embeddings\n",
    "3. **Quantum Computing** - Variational quantum circuits with PennyLane\n",
    "4. **Hybrid Architecture** - Combining classical and quantum layers\n",
    "5. **Model Training** - End-to-end training with PyTorch\n",
    "6. **Evaluation** - Comparing hybrid vs. classical approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üì¶ Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Check versions\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project imports\n",
    "from utils.helpers import set_seed, get_device\n",
    "from utils.smiles_to_graph import smiles_to_graph, MoleculeGraphBuilder\n",
    "from utils.data_loader import load_dataset, create_data_loaders\n",
    "\n",
    "from models.gnn_encoder import GNNEncoder, print_gnn_summary\n",
    "from models.quantum_layer import VariationalQuantumLayer, draw_quantum_circuit, print_quantum_layer_summary\n",
    "from models.hybrid_model import HybridQMolNet, print_hybrid_model_summary\n",
    "from models.baselines import GNNClassifier\n",
    "\n",
    "from training.trainer import Trainer\n",
    "from training.callbacks import EarlyStoppingCallback\n",
    "\n",
    "from evaluation.evaluator import ModelEvaluator\n",
    "from evaluation.metrics import compute_metrics, print_metrics\n",
    "\n",
    "from visualization.molecule_viz import plot_molecule, plot_molecular_graph\n",
    "from visualization.plots import plot_training_curves, plot_confusion_matrix, plot_metrics_comparison\n",
    "from visualization.embedding_viz import plot_embedding_comparison\n",
    "\n",
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üß™ Part 1: Molecular Graph Construction\n",
    "\n",
    "### Theory: From SMILES to Graphs\n",
    "\n",
    "**SMILES** (Simplified Molecular Input Line Entry System) is a string notation for representing molecules. We convert these to **molecular graphs** where:\n",
    "\n",
    "- **Nodes** = Atoms with features (atomic number, degree, charge, hybridization, aromaticity)\n",
    "- **Edges** = Chemical bonds (bidirectional)\n",
    "\n",
    "This graph representation is then processed by Graph Neural Networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example molecules\n",
    "molecules = [\n",
    "    ('CCO', 'Ethanol'),\n",
    "    ('c1ccccc1', 'Benzene'),\n",
    "    ('CC(=O)O', 'Acetic Acid'),\n",
    "    ('CC(=O)Nc1ccc(O)cc1', 'Paracetamol'),\n",
    "]\n",
    "\n",
    "# Build graphs\n",
    "builder = MoleculeGraphBuilder()\n",
    "print(f\"Node feature dimension: {builder.node_feature_dim}\")\n",
    "print(f\"Edge feature dimension: {builder.edge_feature_dim}\")\n",
    "print()\n",
    "\n",
    "for smiles, name in molecules:\n",
    "    data = builder.build(smiles, label=1)\n",
    "    print(f\"{name} ({smiles}):\")\n",
    "    print(f\"  Atoms: {data.x.shape[0]}\")\n",
    "    print(f\"  Bonds: {data.edge_index.shape[1] // 2}\")\n",
    "    print(f\"  Node features shape: {data.x.shape}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize molecular structures\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "for ax, (smiles, name) in zip(axes.flat, molecules):\n",
    "    plot_molecule(smiles, title=name)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize as a graph\n",
    "fig = plot_molecular_graph(\n",
    "    'CC(=O)Nc1ccc(O)cc1', \n",
    "    title='Paracetamol - Graph Representation'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üß† Part 2: Graph Neural Network Encoder\n",
    "\n",
    "### Theory: Message Passing Neural Networks\n",
    "\n",
    "GNNs learn molecular representations through **message passing**:\n",
    "\n",
    "1. **Aggregation**: Each node collects features from its neighbors\n",
    "2. **Update**: Node features are updated based on aggregated messages\n",
    "3. **Pooling**: Node features are combined into a graph-level embedding\n",
    "\n",
    "$$h_v^{(l+1)} = \\sigma\\left(W^{(l)} \\cdot \\text{AGG}\\left(\\{h_u^{(l)} : u \\in \\mathcal{N}(v)\\}\\right)\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GNN encoder\n",
    "gnn_encoder = GNNEncoder(\n",
    "    input_dim=builder.node_feature_dim,\n",
    "    hidden_dim=64,\n",
    "    embedding_dim=32,  # Output: 32-dimensional embedding\n",
    "    num_layers=3,\n",
    "    conv_type='gcn',\n",
    "    pooling='mean',\n",
    ")\n",
    "\n",
    "print_gnn_summary(gnn_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test encoding a molecule\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "# Create batch from example molecules\n",
    "graphs = [builder.build(smiles) for smiles, _ in molecules]\n",
    "batch = Batch.from_data_list(graphs)\n",
    "\n",
    "# Forward pass\n",
    "gnn_encoder.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = gnn_encoder.forward_batch(batch)\n",
    "\n",
    "print(f\"Input: {batch.num_graphs} molecules\")\n",
    "print(f\"Output embeddings shape: {embeddings.shape}\")\n",
    "print(f\"\\nEmbedding vectors:\")\n",
    "for i, (_, name) in enumerate(molecules):\n",
    "    print(f\"  {name}: [{embeddings[i, :5].numpy()}...]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚öõÔ∏è Part 3: Variational Quantum Circuit\n",
    "\n",
    "### Theory: Quantum Neural Networks\n",
    "\n",
    "The variational quantum circuit (VQC) is a parameterized quantum operation:\n",
    "\n",
    "1. **Angle Encoding**: Classical features are encoded as qubit rotations\n",
    "   $$|\\psi_0\\rangle = \\prod_i RY(\\pi \\cdot x_i)|0\\rangle^{\\otimes n}$$\n",
    "\n",
    "2. **Entanglement**: CNOT gates create quantum correlations\n",
    "\n",
    "3. **Parameterized Rotations**: Trainable parameters $\\theta$\n",
    "   $$U(\\theta) = \\prod_l \\left(\\text{CNOT-ring} \\cdot \\prod_i RX(\\theta_i^l)RY(\\theta_i^l)RZ(\\theta_i^l)\\right)$$\n",
    "\n",
    "4. **Measurement**: Pauli-Z expectation values\n",
    "   $$\\langle\\psi|Z_i|\\psi\\rangle \\in [-1, 1]$$\n",
    "\n",
    "Gradients are computed via the **parameter-shift rule**:\n",
    "$$\\frac{\\partial f}{\\partial \\theta} = \\frac{1}{2}\\left[f(\\theta + \\pi/2) - f(\\theta - \\pi/2)\\right]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create quantum layer\n",
    "quantum_layer = VariationalQuantumLayer(\n",
    "    n_qubits=8,      # 8 qubits matching compressed embedding\n",
    "    n_layers=3,      # 3 variational blocks\n",
    "    diff_method='parameter-shift'  # Quantum gradient method\n",
    ")\n",
    "\n",
    "print_quantum_layer_summary(quantum_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the quantum circuit\n",
    "fig = draw_quantum_circuit(n_qubits=8, n_layers=2, figsize=(16, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test quantum layer\n",
    "x_test = torch.randn(2, 8)  # 2 samples, 8 features\n",
    "\n",
    "print(f\"Input shape: {x_test.shape}\")\n",
    "print(f\"Input:\\n{x_test}\")\n",
    "print()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = quantum_layer(x_test)\n",
    "\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Output (expectation values):\\n{output}\")\n",
    "print(f\"\\nOutput range: [{output.min():.3f}, {output.max():.3f}]\")\n",
    "print(\"(Pauli-Z expectation values are in [-1, 1])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üîó Part 4: Hybrid Quantum-Classical Model\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  SMILES ‚Üí Graph ‚Üí GNN ‚Üí Compress ‚Üí [Quantum] ‚Üí Classifier      ‚îÇ\n",
    "‚îÇ                    ‚Üì         ‚Üì          ‚Üì            ‚Üì          ‚îÇ\n",
    "‚îÇ               145D ‚Üí     32D ‚Üí      8D  ‚Üí        8D  ‚Üí    2     ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "The hybrid model combines:\n",
    "- **Classical GNN** for molecular understanding\n",
    "- **Quantum VQC** for non-linear processing\n",
    "- **Classical MLP** for final classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hybrid model\n",
    "hybrid_model = HybridQMolNet(\n",
    "    node_feature_dim=builder.node_feature_dim,\n",
    "    gnn_hidden_dim=64,\n",
    "    gnn_embedding_dim=32,\n",
    "    gnn_layers=3,\n",
    "    n_qubits=8,\n",
    "    quantum_layers=3,\n",
    "    num_classes=2,\n",
    ")\n",
    "\n",
    "print_hybrid_model_summary(hybrid_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test hybrid model on example molecules\n",
    "hybrid_model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = hybrid_model.forward_batch(batch)\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "\n",
    "print(f\"Input: {batch.num_graphs} molecules\")\n",
    "print(f\"Output logits shape: {logits.shape}\")\n",
    "print(f\"\\nPredictions:\")\n",
    "for i, (_, name) in enumerate(molecules):\n",
    "    pred = logits[i].argmax().item()\n",
    "    prob = probs[i, pred].item()\n",
    "    print(f\"  {name}: Class {pred} (confidence: {prob:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèãÔ∏è Part 5: Training the Models\n",
    "\n",
    "Now we train both the hybrid model and a classical baseline to compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "smiles_list, labels = load_dataset(n_samples=300, seed=SEED)\n",
    "\n",
    "train_loader, val_loader, test_loader, dataset = create_data_loaders(\n",
    "    smiles_list, labels,\n",
    "    batch_size=32,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "print(f\"\\nNode feature dimension: {dataset.node_feature_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GNN Baseline\n",
    "print(\"Training GNN Baseline...\")\n",
    "\n",
    "gnn_baseline = GNNClassifier(\n",
    "    node_feature_dim=dataset.node_feature_dim,\n",
    "    num_classes=2,\n",
    ")\n",
    "\n",
    "gnn_trainer = Trainer(\n",
    "    model=gnn_baseline,\n",
    "    device=device,\n",
    "    callbacks=[EarlyStoppingCallback(patience=10)],\n",
    "    model_name=\"GNN_Baseline\",\n",
    ")\n",
    "\n",
    "gnn_history = gnn_trainer.fit(\n",
    "    train_loader, val_loader,\n",
    "    num_epochs=30,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Hybrid Model (this will take longer due to quantum simulation)\n",
    "print(\"Training Hybrid QMolNet...\")\n",
    "print(\"(Note: Quantum simulation is computationally intensive)\")\n",
    "\n",
    "hybrid_train = HybridQMolNet(\n",
    "    node_feature_dim=dataset.node_feature_dim,\n",
    "    n_qubits=8,\n",
    "    quantum_layers=2,\n",
    "    num_classes=2,\n",
    ")\n",
    "\n",
    "hybrid_trainer = Trainer(\n",
    "    model=hybrid_train,\n",
    "    device=device,\n",
    "    callbacks=[EarlyStoppingCallback(patience=15)],\n",
    "    model_name=\"Hybrid_QMolNet\",\n",
    ")\n",
    "\n",
    "hybrid_history = hybrid_trainer.fit(\n",
    "    train_loader, val_loader,\n",
    "    num_epochs=30,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# GNN\n",
    "ax = axes[0]\n",
    "ax.plot(gnn_history.train_loss, label='Train Loss')\n",
    "ax.plot(gnn_history.val_loss, label='Val Loss')\n",
    "ax.set_title('GNN Baseline Training')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend()\n",
    "\n",
    "# Hybrid\n",
    "ax = axes[1]\n",
    "ax.plot(hybrid_history.train_loss, label='Train Loss')\n",
    "ax.plot(hybrid_history.val_loss, label='Val Loss')\n",
    "ax.set_title('Hybrid QMolNet Training')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Part 6: Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate GNN Baseline\n",
    "gnn_evaluator = ModelEvaluator(gnn_baseline, device=device, model_name=\"GNN Baseline\")\n",
    "gnn_metrics = gnn_evaluator.evaluate(test_loader)\n",
    "gnn_evaluator.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Hybrid Model\n",
    "hybrid_evaluator = ModelEvaluator(hybrid_train, device=device, model_name=\"Hybrid QMolNet\")\n",
    "hybrid_metrics = hybrid_evaluator.evaluate(test_loader)\n",
    "hybrid_evaluator.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare metrics\n",
    "all_metrics = {\n",
    "    'GNN Baseline': gnn_metrics,\n",
    "    'Hybrid QMolNet': hybrid_metrics,\n",
    "}\n",
    "\n",
    "fig = plot_metrics_comparison(all_metrics, title='Model Performance Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "cm_gnn = gnn_evaluator.get_confusion_matrix()\n",
    "cm_hybrid = hybrid_evaluator.get_confusion_matrix()\n",
    "\n",
    "sns.heatmap(cm_gnn, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "axes[0].set_title('GNN Baseline')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('True')\n",
    "\n",
    "sns.heatmap(cm_hybrid, annot=True, fmt='d', cmap='Greens', ax=axes[1])\n",
    "axes[1].set_title('Hybrid QMolNet')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embeddings\n",
    "embeddings, labels = hybrid_evaluator.get_embeddings(test_loader, layer='gnn')\n",
    "\n",
    "fig = plot_embedding_comparison(\n",
    "    embeddings, labels,\n",
    "    title='Learned Molecular Embeddings',\n",
    "    class_names=['Inactive', 'Active']\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Molecular Graphs**: SMILES strings are converted to graphs with atom features and bond connectivity\n",
    "\n",
    "2. **GNN Encoding**: Message-passing layers learn molecular representations by aggregating neighbor information\n",
    "\n",
    "3. **Quantum Processing**: The VQC uses angle encoding and parameterized rotations to process compressed embeddings\n",
    "\n",
    "4. **Hybrid Architecture**: Combining classical and quantum layers enables novel computational capabilities\n",
    "\n",
    "5. **Parameter-Shift Gradients**: Quantum circuits are differentiable, enabling end-to-end training\n",
    "\n",
    "### Research Directions\n",
    "\n",
    "- Larger datasets (BBBP, Tox21, HIV)\n",
    "- More qubits and deeper circuits\n",
    "- Different quantum ansatzes\n",
    "- Hardware execution (IBM Quantum, IonQ)\n",
    "\n",
    "---\n",
    "\n",
    "**Thank you for exploring Hybrid QMolNet!** üß¨‚öõÔ∏è"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
